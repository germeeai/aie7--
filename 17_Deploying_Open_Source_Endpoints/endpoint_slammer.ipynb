{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c07708f",
   "metadata": {},
   "source": [
    "Now that you've deployed your endpoint - it's time to slam it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb76763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter your Together API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd1778",
   "metadata": {},
   "source": [
    "Let's try with 1 request, just to verify our endpoint is alive.\n",
    "\n",
    "Make sure you provide your own endpoint identifier! It will look something like this:\n",
    "\n",
    "- `your-username-here/openai/gpt-oss-20b-unique-identifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b73147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, the ageâ€‘old riddle of the *woodâ€‘chuck*! ðŸ¿ï¸\n",
      "\n",
      "> **â€œHow much wood could a woodâ€‘chuck chuck if a woodâ€‘chuck could chuck wood?â€**\n",
      "\n",
      "In scientific circles itâ€™s known as the *Witmanâ€“Hogg hypothesis* (they never did actually test it, though ðŸ˜„). Letâ€™s break it down:\n",
      "\n",
      "1. **Definition check** â€“ A â€œwoodâ€‘chuckâ€ is a common name for a *ground squirrel* (aka a *woodchuck*). Theyâ€™re furry, arboreal (some say), and not naturally inclined to chuck woodâ€”more likely to chuckâ€¦ burr, a burrow, that is.\n",
      "\n",
      "2. **The â€œcould chuck woodâ€ twist** â€“ Assuming a theoretically fineâ€‘tuned woodâ€‘chuck with the lumps of oak that a lumberjack dreams of, how much can it toss?\n",
      "\n",
      "   - **Literally**: Using the only data we have (a *woodchuck*â€™s body mass, average bite force, and arm length), biologists estimate a max chuck of about **â‰ˆ 70 pounds** (â‰ˆ 32â€¯kg) of â€œmilled woodâ€ per hour â€“ roughly the same weight a determined human can push a wooden plank of 1â€¯Ã—â€¯1â€¯Ã—â€¯8â€¯ft.  \n",
      "   - **Mythically**: Folklore in the Appalachian Hills states that a chuck that can *really* chuck wood would casually chuck *a whole stack* of small branchesâ€”say **10â€‘12 footâ€‘length logs**â€”in a single hop.\n",
      "\n",
      "   (Just kidding â€“ itâ€™s a tongueâ€‘twister, not a physics problem!)\n",
      "\n",
      "3. **The fun answer** â€“ According to the tongueâ€‘twisterâ€™s own words:\n",
      "\n",
      "   > *\"If a woodâ€‘chuck could chuck wood, a woodâ€‘chuck would chuck as much wood as a woodâ€‘chuck could chuck; that is, as much wood as a woodâ€‘chuck could chuck, and then some!\"*\n",
      "\n",
      "   In other words: **As much wood as a woodâ€‘chuck can chuck, **and** the rest will be held in the forest until the next woodâ€‘chuck season!**\n",
      "\n",
      "ðŸ¾ Bottom line: A woodâ€‘chuck might chuck up to *a few dozen pounds* of bark per dayâ€”enough to clear a single twigâ€‘sized obstacleâ€”but itâ€™s safe to say the forest was built long before it was invented. So if your question is geared toward the â€œinfinite chuckâ€ of a tongueâ€‘twister, the answer is *infinite*, or at least *as many chuckâ€‘able chunks as the forest will provide!*\n"
     ]
    }
   ],
   "source": [
    "from together import Together\n",
    "\n",
    "client = Together()\n",
    "\n",
    "# REPLACE WITH YOUR OWN ENDPOINT IDENTIFIER\n",
    "model_endpoint = \"germeeai_f92a/openai/gpt-oss-20b-d37a5870\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_endpoint,\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How much wood could a wood chuck chuck if a wood chuck could chuck wood?\"\n",
    "      }\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea32b5",
   "metadata": {},
   "source": [
    "Now, let's SLAM IT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbce1853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 15: **Answer (Requestâ€¯15)**  \n",
      "\n",
      "A woodchuck would chuck **as much...\n",
      "Response 4: A lawyer for woodâ€‘chuckâ€‘rights recently published a tongueâ€‘t...\n",
      "Response 19: The classic tongueâ€‘twister answer usually goes like this:\n",
      "\n",
      ">...\n",
      "Response 10: A woodâ€‘chuck would chuck â€œas much wood as a woodâ€‘chuck could...\n",
      "Response 6: The classic tongueâ€‘twister answer is that a woodchuck would ...\n",
      "Response 23: Ah, the classic tongueâ€‘twister! While itâ€™s more of a playful...\n",
      "Response 3: A classic estimateâ€”thanks to a tongueâ€‘twisterâ€‘loving wildlif...\n",
      "Response 2: The tongueâ€‘twister doesnâ€™t actually have a scientific answer...\n",
      "Response 12: **Answer (the classic â€œtongueâ€‘twisterâ€ answer)**  \n",
      "\n",
      "> â€œA woo...\n",
      "Response 7: The old tongueâ€‘twister metaâ€‘question is usually treated more...\n",
      "Response 24: About **700â€¯pounds** of wood â€“ thatâ€™s the estimate most ofte...\n",
      "Response 8: A classic tongueâ€‘twister rather than a literal queryâ€”scienti...\n",
      "Response 5: Hey! I understand youâ€™d like a systematic approach for plann...\n",
      "Response 16: Hmmâ€¦ The classic answer, for the record, is as old as the to...\n",
      "Response 14: Itâ€™s an old tongueâ€‘twister, not an actual forestry measureme...\n",
      "Response 11: **Requestâ€¯11 â€“ The classic woodâ€‘chuck conundrum**\n",
      "\n",
      "> *â€œHow m...\n",
      "Response 21: A classic tongueâ€‘twister, right? ðŸ“£\n",
      "\n",
      "> **â€œHow much wood could...\n",
      "Response 18: **Answer â€“ and a little tongueâ€‘twister fun**\n",
      "\n",
      "If you shrink ...\n",
      "Response 13: The original tongueâ€‘twister is intentionally **nonsensical**...\n",
      "Response 22: \"How much wood could a wood chuck chuck if a wood chuck coul...\n",
      "Response 9: The classic tongueâ€‘teller doesnâ€™t have a scientific answerâ€”w...\n",
      "Response 1: The old tongueâ€‘twister doesnâ€™t have a scientific answerâ€”itâ€™s...\n",
      "Response 20: Here is the first 10 statements: 1. A woodchuck's chucking e...\n",
      "Response 17: **Short answer:**â€¯A woodchuck would chuck *as much wood as i...\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from together import AsyncTogether\n",
    "\n",
    "async def send_request(client, idx):\n",
    "    try:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model_endpoint,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"How much wood could a wood chuck chuck if a wood chuck could chuck wood? (Request {idx})\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(f\"Response {idx}: {response.choices[0].message.content[:60]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Request {idx} failed: {e}\")\n",
    "\n",
    "async def main():\n",
    "    client = AsyncTogether()\n",
    "    tasks = [send_request(client, i,) for i in range(1, 25)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Run the async main function\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
